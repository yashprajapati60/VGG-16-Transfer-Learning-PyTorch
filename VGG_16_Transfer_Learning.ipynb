{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#                                           Transfer Learning using PyTorch"
      ],
      "metadata": {
        "id": "lHjLYTUsHa8E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H1SYWeiHVuu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDS30AISIS-m",
        "outputId": "3e4a2394-6e9c-4160-f541-6ab8f0f4e02e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/fmnist_small.csv')\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7oSL40pIsy3",
        "outputId": "e6d8284c-1a20-4755-9f6c-47548676c816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 785)"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Train_test_split"
      ],
      "metadata": {
        "id": "9fLur6-dJwlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random.mtrand import random\n",
        "x = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=22)"
      ],
      "metadata": {
        "id": "JXDeTdXJJl2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "metadata": {
        "id": "xIkoedRJKE_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformations"
      ],
      "metadata": {
        "id": "p1js32h2hZWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "wXj36VI0KMXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    # transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "WFYmnk74huiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "class customdset(Dataset):\n",
        "\n",
        "  def __init__(self, features, labels, transform):\n",
        "    super().__init__()\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.features)\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    # resize to (28, 28)\n",
        "    image = self.features[index].reshape(28,28)\n",
        "    # change data type to np.uint8\n",
        "    image = image.astype(np.uint8)\n",
        "    # change black & white to color\n",
        "    image = np.stack([image]*3, axis = -1) #(3, 28, 28) # PIL want to img format as (width, height, channels) so we should use axis =-1\n",
        "    # convert array to PIL image\n",
        "    image = Image.fromarray(image)\n",
        "    # apply transformation\n",
        "    image = self.transform(image)\n",
        "    # return index\n",
        "    return image, torch.tensor(self.labels[index], dtype = torch.long)"
      ],
      "metadata": {
        "id": "u21ODuFHinsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset & Loader"
      ],
      "metadata": {
        "id": "nkXh828NmAP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = customdset(x_test, y_test, transform = custom_transform)\n",
        "train_dataset = customdset(x_train, y_train, transform = custom_transform)"
      ],
      "metadata": {
        "id": "MaBKhTCElz0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = False, pin_memory=True)"
      ],
      "metadata": {
        "id": "zzWLvmo4mjHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- import pre-trained model"
      ],
      "metadata": {
        "id": "HcO-wo4om2Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "vgg16 = models.vgg16(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBOvuQzpmtnh",
        "outputId": "c6cdad28-4277-485e-e23a-b42e201e3488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze features training\n",
        "for param in vgg16.features.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "TtJZHxP5nt28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# replace classifier with our new classifier\n",
        "vgg16.classifier = nn.Sequential(\n",
        "    nn.Linear(25088, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(1024, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 10)\n",
        "    )"
      ],
      "metadata": {
        "id": "-FCi83cRn8CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOJhMY8dnYxJ",
        "outputId": "290c5e47-ce58-432f-88bd-d4b873880e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (4): ReLU()\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16 = vgg16.to(device)"
      ],
      "metadata": {
        "id": "vpYlZdr1niTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "epochs = 15"
      ],
      "metadata": {
        "id": "k0ZokHPsqCa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vgg16.classifier.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "Q2pNF3jXqJEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training LOOP"
      ],
      "metadata": {
        "id": "AFmFW4rBqi2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "  total_epoch_loss = 0\n",
        "\n",
        "  for batch_features, batch_labels in train_loader:\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)# move data to GPU\n",
        "    outputs = vgg16(batch_features) # forward pass\n",
        "    loss = criterion(outputs, batch_labels) # loss calculation\n",
        "    optimizer.zero_grad() # clear gradients\n",
        "    loss.backward() # backward pass\n",
        "    optimizer.step() # update weights\n",
        "    total_epoch_loss += loss.item()\n",
        "  avg_loss = total_epoch_loss/len(train_loader)\n",
        "  print(f\"epoch: {epoch+1}, loss: {avg_loss}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s19z-Ov-qiLJ",
        "outputId": "a75a702b-8998-4be8-cc69-b86e16a26ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss: 2.328344462712606\n",
            "epoch: 2, loss: 2.294149227142334\n",
            "epoch: 3, loss: 2.272504065831502\n",
            "epoch: 4, loss: 2.2487198225657146\n",
            "epoch: 5, loss: 2.215827252070109\n",
            "epoch: 6, loss: 2.2004471397399903\n",
            "epoch: 7, loss: 2.1750100485483803\n",
            "epoch: 8, loss: 2.1748464504877725\n",
            "epoch: 9, loss: 2.1885434786478677\n",
            "epoch: 10, loss: 2.1547291310628256\n",
            "epoch: 11, loss: 2.1548508739471437\n",
            "epoch: 12, loss: 2.1634185949961346\n",
            "epoch: 13, loss: 2.1162214263280235\n",
            "epoch: 14, loss: 2.1332523727416994\n",
            "epoch: 15, loss: 2.116058071454366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tabI9dTxr4Xd",
        "outputId": "b1417c41-ff8b-4656-d3f7-a0a974120149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  for batch_features, batch_labels in test_loader:\n",
        "    batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
        "\n",
        "    outputs = vgg16(batch_features)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "    total = total + batch_labels.size(0)\n",
        "\n",
        "    correct = correct + (predicted == batch_labels).sum().item()\n",
        "\n",
        "print(correct/total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpbzlWoR2u8F",
        "outputId": "efc4ec23-c785-4112-ff58-492103ccea70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.20666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQ4g5Ao6214L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}